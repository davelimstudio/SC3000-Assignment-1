{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ced3ee",
   "metadata": {},
   "source": [
    "# NanoGPT + Math\n",
    "Team Members and Contribution\n",
    "- Lim Jun Yan (Leader)\n",
    "    - Led the project and coordinated team efforts\n",
    "    - Trained the model and conducted evaluations\n",
    "    - Analysed results and validated findings\n",
    "- Teo Wei Xiang\n",
    "    - Provided dataset and assisted in data preprocessing\n",
    "    - Conducted dataset analysis and visualization\n",
    "    - Assisted with model training and fine-tuning\n",
    "- Daryl Goh Zhuan Boon\n",
    "    - Assisted in model training and evaluation\n",
    "    - Finetuned hyperparameters and analyzed results\n",
    "    - Analyzed model errors and provided insights\n",
    "\n",
    "All team members contributed to the writing and editing of the final report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a869a",
   "metadata": {},
   "source": [
    "### Step 1: Install necesscary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9de0",
   "metadata": {},
   "source": [
    "### Step 2: Package imports and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d8ac8",
   "metadata": {},
   "source": [
    "### Training and Hyperparameters\n",
    "\n",
    "| Parameter  | Value         | Description                                                                                                                                                                                                                                                                           |\n",
    "|------------|---------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| beta       | 0.5           | Scaling factor for the DPO loss on separating the positive & negative pairs. If beta is small (e.g. 0.1), small difference between the pairs log-probs pushes the model to favour positive (larger gradient), while if it is large, difference are tolerated more  (smaller gradient) |\n",
    "| base_lr    | 1e-4          | The initial step size for weight updates during training. Learning rate for the optimizer.                                                                                                                                                                                            |\n",
    "| min_lr     | base_lr * 0.1 | The minimum learning rate for the scheduler to decay to.                                                                                                                                                                                                                              |\n",
    "| epochs     | 15            | Number of complete passes through the training dataset.                                                                                                                                                                                                                               |\n",
    "| batch_size | pow(2^9), 512 | Number of samples processed before the model is updated.                                                                                                                                                                                                                              |\n",
    "\n",
    "\n",
    "### Sequence Generation Parameters\n",
    "| Parameter      | Value | Description                                                                                                                                                                                   |\n",
    "|----------------|-------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| max_length     | 64    | Maximum input sequence length for the model. Based on testing, we saw max length around 61-62 so 64 should be fine (helps reduce training time if low)                                        |\n",
    "| num_samples    | 1     | Number of sequences to generate for each input prompt. Each input prompt produces 1 output sample during inferences                                                                           |\n",
    "| max_new_tokens | 100   | Maximum number of new tokens to generate during inference. Assuming we only output math qns, limit token gen size to 100                                                                      |\n",
    "| temperature    | 0.8   | Controls the randomness of predictions. Lower means more deterministic, higher means more randomness, we left this default as it seems to provides a good blance between variety and accuracy |\n",
    "| top_k          | 200   | Restricts generation to the top 200 most likely tokens at each step, ensuring coherent and relevant outputs                                                                                   |\n",
    "\n",
    "\n",
    "### Tokeniszer\n",
    "\n",
    "We use the `meta.pkl` tokenizer, which is basically a GPT-2 tokenizer. This tokenizer is essential for converting text inputs into token IDs that the model can process, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dd92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device to use: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "# import shutil\n",
    "# shutil.copy('/kaggle/input/script/other/default/1/model.py', '/kaggle/working/model.py')\n",
    "from model import GPT, GPTConfig\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# Configuration\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "beta = 0.5\n",
    "base_lr = 1e-4\n",
    "min_lr = base_lr * 0.1\n",
    "epochs = 20\n",
    "#We used kaggle hence we could do batch_size 1024\n",
    "#batch_size = pow(2,9)\n",
    "batch_size = 64\n",
    "#Based on testing, we saw max length around 61-62 so 64 should be fine (helps reduce training time if low)\n",
    "max_length = 64\n",
    "num_samples = 1\n",
    "# Assuming we only output math qns, limit token gen size to 100\n",
    "max_new_tokens = 100\n",
    "# Leave Temp and k default, to allow more variation in ans\n",
    "temperature = 0.8 \n",
    "top_k = 200 \n",
    "# tokenizer\n",
    "#with open(\"../input/gpt/pytorch/default/1/meta.pkl\", \"rb\") as f:\n",
    "with open(\"../sft/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "def encode(s): return [stoi[c] for c in s]\n",
    "def decode(l): return ''.join([itos[i] for i in l])\n",
    "print(\"Device to use: \"+device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35e6",
   "metadata": {},
   "source": [
    "### Step 3: Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a87f15",
   "metadata": {},
   "source": [
    "For step 3, we did not edit the predefined functions provided. However, to deepen our understanding of the entire structure we summarized these 3 functions as.\n",
    "\n",
    "**compute_logprob(input_ids)**:\n",
    "\n",
    "This function computes how likely the model will produce the pos/neg tokens. It considers the entire output of the model except the padding tokens. Knowing this allowed us to understand that the model computes loss prob using the chances of tokens generating sequencially.\n",
    "\n",
    "<br/>\n",
    "\n",
    "**pad_or_truncate(seq, max_length)**:\n",
    "\n",
    "Pads or cut off the pos/neg. Uses variable max_length, adds pad or cut off if necessary. (not desirable) Knowing this made us consider the max_length variable, which we left at 64 due to realizing the datalines were mostly 61-62 length.\n",
    "\n",
    "<br/>\n",
    "\n",
    "**get_batches(lines, batch_size):**\n",
    "\n",
    "Used at the start of each epoch during training (step 7), prepares the data for training the model. Cuts of data by len(data)%batch_size. Therefore, if the data cannot fit the batch_size, it will be discarded. This is where it is tokenized and padded for tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprob(input_ids):\n",
    "    inputs = input_ids[:, :-1]\n",
    "    targets = input_ids[:, 1:]\n",
    "    logits, _ = gpt(inputs, full_seq=True)\n",
    "    B, T, V = logits.size()\n",
    "    logits_flat = logits.reshape(-1, V)\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=0, reduction='none')\n",
    "    loss = loss.reshape(B, T)\n",
    "    attention_mask = (targets != 0).float()\n",
    "    loss = (loss * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
    "    return -loss \n",
    "\n",
    "def pad_or_truncate(seq, max_length):\n",
    "    return seq[-max_length:] if len(seq) > max_length else seq + [0] * (max_length - len(seq))\n",
    "\n",
    "def get_batches(lines, batch_size):\n",
    "    random.shuffle(lines)\n",
    "    #for l in lines:\n",
    "    #    print(l[1])\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        batch = lines[i:i+batch_size]\n",
    "        if len(batch) < batch_size:\n",
    "            continue\n",
    "        neg_inputs = [pad_or_truncate(encode(p['negative'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        pos_inputs = [pad_or_truncate(encode(p['positive'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        neg_tensor = torch.tensor(neg_inputs, dtype=torch.long, device=device)\n",
    "        pos_tensor = torch.tensor(pos_inputs, dtype=torch.long, device=device)\n",
    "        yield neg_tensor, pos_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9eba",
   "metadata": {},
   "source": [
    "### Step 4: Load the pretrained NanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(74, 348)\n",
       "    (wpe): Embedding(256, 348)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=348, out_features=1044, bias=False)\n",
       "          (c_proj): Linear(in_features=348, out_features=348, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=348, out_features=1392, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1392, out_features=348, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=348, out_features=74, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ckpt = torch.load(\"../input/gpt/pytorch/default/1/gpt.pt\", map_location=device)\n",
    "ckpt = torch.load(\"../sft/gpt.pt\", map_location=device)\n",
    "gptconf = GPTConfig(**ckpt['model_args'])\n",
    "gpt = GPT(gptconf)\n",
    "state_dict = ckpt['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "gpt.to(device).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feafc5a",
   "metadata": {},
   "source": [
    "### Step 5: Load Data (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b259f3",
   "metadata": {},
   "source": [
    "Our goal is to build a math training dataset that contains simple arithmetic problems and their solutions, following by some reasoning. For example:\n",
    "\n",
    "```bash\n",
    "98/x=14,x=? The answer is 7 because 98/14 equals 7.\n",
    "8*100=? The answer is 800 because 8*100 equals 800.\n",
    "```\n",
    "\n",
    "The dataset cover basic arithmetic operations such as addition, subtraction, multiplication, and division, and there could be algebraic expressions involved.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### *Attempts timeline*\n",
    "\n",
    "---\n",
    "\n",
    "1. **Random generation of arithmetic problems and solutions using Python's built-in `random` library.** This method is straightforward but may lack diversity and complexity in the problems generated as shown below:\n",
    "\n",
    "```yaml\n",
    "[\n",
    "  {\n",
    "    \"positive\": \"x*35=70,x=? The answer is 2 because 70/35 equals 2.\",\n",
    "    \"negative\": \"x*35=70,x=? Sorry, I do not know!\",\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"83/83=? The answer is 1 because 83/83 equals 1.\",\n",
    "    \"negative\": \"83/83=? Sorry, I do not know!\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This approach yielded a basic dataset but did not sufficiently challenge the model's reasoning capabilities.\n",
    "\n",
    "Random sampling missed certain pairs and produces inconsistent coverage, leading to gaps in the dataset. For example, we found that some multiplication/division pairs were underrepresented.\n",
    "\n",
    "Also, we learnt that the \"negative\" responses included a bad character \"!\" where the tokenizer did not handle it well. \n",
    "\n",
    "---\n",
    "\n",
    "2. **Exhaustive, commutative operations to create a more comprehensive dataset.** This method ensures coverage of various arithmetic operations but may still lack depth in reasoning. We aim for a complete coverage of every possible 1 and 2-digits pair (e.g., all combinations from 0–99) while still applying the commutative rule to avoid redundant duplicates\n",
    "\n",
    "```yaml\n",
    "[\n",
    "  {\n",
    "    \"negative\": \"x/99=96,x=? Sorry, I do not know.\",\n",
    "    \"positive\": \"x/99=96,x=? The answer is 9504 because 99*96 equals 9504.\"\n",
    "  },\n",
    "  {\n",
    "    \"negative\": \"x/99=97,x=? Sorry, I do not know.\",\n",
    "    \"positive\": \"x/99=97,x=? The answer is 9603 because 99*97 equals 9603.\"\n",
    "  },\n",
    "  {\n",
    "    \"negative\": \"x/99=98,x=? Sorry, I do not know.\",\n",
    "    \"positive\": \"x/99=98,x=? The answer is 9702 because 99*98 equals 9702.\"\n",
    "  },\n",
    "  {\n",
    "    \"negative\": \"x/99=99,x=? Sorry, I do not know.\",\n",
    "    \"positive\": \"x/99=99,x=? The answer is 9801 because 99*99 equals 9801.\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "This approach provided a more deterministic, and comprehensive dataset.\n",
    "\n",
    "But the orderliness of the dataset was not ideal for preference learning, as the model could easily pick up on patterns unrelated to reasoning (e.g., always higher numbers in positive answers).\n",
    "\n",
    "We noticed the formatting of the output was still not ideal, with some inconsistencies in phrasing and structure. Hence, further refinements were needed.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Varying \"negative\" with graded wrongness.** To support preference learning, we added negative responses that were wrong in controlled ways (e.g., small arithmetic slip, off-by-one, confident but incorrect rationale).\n",
    "\n",
    "```yaml\n",
    "[\n",
    "  {\n",
    "    \"positive\": \"82+91=? The answer is 173 because 82+91 equals 173.\",\n",
    "    \"negative\": \"82+91=? The answer is 172 because 82+91 equals 172.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"388*32=? The answer is 12416 because 388*32 equals 12416.\",\n",
    "    \"negative\": \"388*32=? The answer is 12804 because 388*32 equals 12804.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"7+4=? The answer is 11 because 7+4 equals 11.\",\n",
    "    \"negative\": \"7+4=? The answer is 12 because 7+4 equals 12.\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "After iterating through different negatives, we settled with \"Sorry, I don't know.\" as negatives. We believe due to having variations, made the model output results undesirable. \n",
    " \n",
    "We believe its due to dataset size and learning rate we have configured. If we decreased learning rate while increasing epoch the model starts to gain the system by outputting small changes in A, B or C.\n",
    "\n",
    "However, if we train at a high learning rate, the model is unable to detect a pattern which causes it to catastrophicly forget not only its english abilities, but output gibberish most of the time.\n",
    "\n",
    "Maybe with a larger coverage of edge cases using a larger dataset, we could avoid this. However, due to lack of GPU time available, we decided to settle for less comprehensive reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "4. **SFT on the \"postive\" dataset.** We ran a short SFT pass on only the positive answers to check if formatting/structure needed supervised bootstrap. Observation: not strictly necessary—the model already picked up the target format reliably from the preference setup and task simplicity.\n",
    "\n",
    "```yaml\n",
    "[\n",
    "  {\n",
    "    \"positive\": \"2-1=? The answer is 1 because 2-1 equals 1.\",\n",
    "    \"prompt\": \"2-1=?\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"x-1=1,x=? The answer is 2 because 1+1 equals 2.\",\n",
    "    \"prompt\": \"x-1=1,x=?\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"2-x=1,x=? The answer is 1 because 2-1 equals 1.\",\n",
    "    \"prompt\": \"2-x=1,x=?\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "We also tried to implement a mixed SFT + DPO training loop to help enforce the formatting.\n",
    "\n",
    "Justification: by mixing SFT and DPO, we can ensure that the model not only learns to prefer correct answers over incorrect ones but also adheres to the desired output format consistently. This dual approach helps reinforce both accuracy and structure in the model's responses.\n",
    "\n",
    "However, we found that this mixed approach complicated the training process without significant gains in performance. The model was already learning the format well from the DPO training alone, so the added complexity of mixing SFT did not yield proportional benefits.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "5. **Back to commutative with behvaioral tweaks.** We returned to the commutative dataset generation, but added more behavioral diversity (e.g., varying reasoning styles, different phrasings). But we skewed reducing cases involving 1 to ensure the model learned these fundamental properties well.\n",
    "\n",
    "```yaml\n",
    "[  {\n",
    "    \"positive\": \"0+0=? The answer is 0 because 0+0 equals 0.\",\n",
    "    \"negative\": \"0+0=? Sorry, I do not know.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"x+0=0,x=? The answer is 0 because 0-0 equals 0.\",\n",
    "    \"negative\": \"x+0=0,x=? Sorry, I do not know.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"0+x=0,x=? The answer is 0 because 0-0 equals 0.\",\n",
    "    \"negative\": \"0+x=0,x=? Sorry, I do not know.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"0-0=? The answer is 0 because 0-0 equals 0.\",\n",
    "    \"negative\": \"0-0=? Sorry, I do not know.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"x-0=0,x=? The answer is 0 because 0+0 equals 0.\",\n",
    "    \"negative\": \"x-0=0,x=? Sorry, I do not know.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"0-x=0,x=? The answer is 0 because 0-0 equals 0.\",\n",
    "    \"negative\": \"0-x=0,x=? Sorry, I do not know.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"0*0=? The answer is 0 because 0*0 equals 0.\",\n",
    "    \"negative\": \"0*0=? Sorry, I do not know.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"x*0=0,x=? The answer is 0 because 0/0 equals 0.\",\n",
    "    \"negative\": \"x*0=0,x=? Sorry, I do not know.\"\n",
    "  },\n",
    "  {\n",
    "    \"positive\": \"0*x=0,x=? The answer is 0 because 0/0 equals 0.\",\n",
    "    \"negative\": \"0*x=0,x=? Sorry, I do not know.\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "This final approach yielded a robust dataset that balanced coverage, diversity, and reasoning complexity. The goal of this dataset is to teach the model to reply in the format: \"PROMPT The answer is A because B is C\"\n",
    "\n",
    "PROMPT: Being the prompt either in algebra or arithmetic\n",
    "A: Answer\n",
    "B: Reasoning\n",
    "C: Answer\n",
    "\n",
    "For each equation, we generate arithmetic and algebra versions for it.\n",
    "For Positive generation we generated.\n",
    "1) behavior when 0 (+-*) occurs.\n",
    "2) behavior when 1 (*/) occurs.\n",
    "3) behavior of comutativity.\n",
    "4) behavior of additions.\n",
    "5) behavior of tens multiplications.\n",
    "6) behavior of squares.\n",
    "\n",
    "Due to the small dataset size, the model often picks up bad habbits of commonly occuring word patterns. E.g. we had issue with it generating \"1\" and \"1+1\" often. To reduce this behavoir, we skewed number generation to reduce occurences of \"1\" so that the dataset is more balanced. \n",
    "\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Loading the final dataset:\n",
    "\n",
    "We also shuffled the dataset to ensure the model does not pick up on ordering patterns and split into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237390 lines were loaded\n",
      "100 test lines were loaded\n",
      "237290 training lines were loaded\n"
     ]
    }
   ],
   "source": [
    "# Load data from dataset_final.json\n",
    "lines = []\n",
    "# base_path = \"../input/pos-mix-neg/dataset_final.json\"\n",
    "base_path = \"./pos_neg_pairs.json\"\n",
    "with open(base_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines.extend(json.load(f))\n",
    "print(str(len(lines))+\" lines were loaded\")\n",
    "\n",
    "test_lines=[]\n",
    "random.shuffle(lines)\n",
    "#Used to test model performance that are outside of the dataset that was used to train, although typically we use 40% but.. :)\n",
    "test_lines=lines[0:100]\n",
    "lines=lines[100:]\n",
    "\n",
    "# load data from testing_dataset.json\n",
    "# # This is used to test model's correctness\n",
    "# test_lines=[]\n",
    "# base_path=\"../input/pos-mix-neg/testdata_final.json\"\n",
    "# with open(base_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     test_lines.extend(json.load(f))\n",
    "print(str(len(test_lines))+\" test lines were loaded\")\n",
    "print(str(len(lines))+\" training lines were loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f81f",
   "metadata": {},
   "source": [
    "### Step 6: Build the optimizer and scheduler (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e753f2",
   "metadata": {},
   "source": [
    "__Optimizer__\n",
    "For our optimizer (optimizer=torch.optim.AdamW(gpt.parameters(), lr=base_lr)), we decided to go with torch.optim.AdamW to update the model's parameters (gpt.parameters()) via gradients to minimize DPO loss. \n",
    "\n",
    "We use AdamW as it makes training more stable, helps the model avoid overfitting, and performs better on test data.\n",
    "\n",
    "__Calculation of Total Training Steps__\n",
    "Total steps calculation:\n",
    "Dataset: 237,290 training examples (Originally 237390 but 100 taken out for testing)\n",
    "Batch size: 512\n",
    "Epochs: 15\n",
    "Steps per epoch ≈ 237,290 ÷ 512 ≈ 463\n",
    "Total steps = 463 × 15 = 6,945\n",
    "\n",
    "__Scheduler__\n",
    "For our scheduler (scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=min_lr)) we use CosineAnnealingLR to smoothly decrease the learning rate during the model training. It starts with the initial learning rate and will gradually decrease in a smooth curve to a minimum value (min_lr). This will allow the model to converge more steadily.\n",
    "\n",
    "The benefits for the DPO are namely:\n",
    "Reduces early over-correction to preference signals.\n",
    "Enables continued fine-tuning via a non-zero minimum LR.\n",
    "\n",
    "__Training Dynamics over the Epochs__\n",
    "Learning rate schedule:\n",
    "Epoch 1: LR ≈ 1e-4 (starting learning rate)\n",
    "Epoch 5: LR ≈ 7e-5\n",
    "Epoch 10: LR ≈ 4e-5\n",
    "Epoch 15: LR ≈ 1e-5 (minimum learning rate, min_lr)\n",
    "\n",
    "This shows that:\n",
    "Having larger steps early helps preference alignment\n",
    "Having smaller steps later support refinement\n",
    "The eta_min keeps training active throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0c400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer and scheduler ready\n",
      "Total steps: 9260\n"
     ]
    }
   ],
   "source": [
    "# recommend to use the AdamW optimizer \n",
    "optimizer=torch.optim.AdamW(gpt.parameters(), lr=base_lr)\n",
    "total_steps = len(lines) // batch_size * epochs\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=min_lr)\n",
    "print(\"Optimizer and scheduler ready\")\n",
    "print(\"Total steps: \"+str(total_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66199",
   "metadata": {},
   "source": [
    "### Step 7: Begin training (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0789b22",
   "metadata": {},
   "source": [
    "The training phase uses the log function provided by the template.\n",
    "\n",
    "__Formula__: `loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1`\n",
    "\n",
    "---\n",
    "\n",
    "__-F.logsigmoid((pos_logprob - neg_logprob) / beta).mean()__:\n",
    "\n",
    "The first part of the formula is the main component for DPO. Also known as ranking component. (1) If pos_logprob is higher than neg_logprob, result inside will be positive. (2) Else it will be negative. Its important to note this as the logsigmoid turns (1) into a value close to 0. While in case (2) the value generated is a large negative number. With the \"-\" outside of the formula, turns case (2) into a large positive number. Hence, when the chances of generating the negative is large, it output a large number to signal to the model that the current output is bad.\n",
    "\n",
    "Another thing to note is the beta, which scales the result of pos-neg based on beta. Hence, by setting beta lower, e.g. when beta=0.1, /0.1 will scale the difference by x10 compared to when beta=0.5, /0.5 will scale the difference by x2 only.\n",
    "\n",
    "__-pos_logprob.mean() * 0.1__: \n",
    "\n",
    "The second part of the formula is called a regularization component. Which rewards the model higher when probability of generating pos is higher. This rewards the model to make positive examples as similar as possible. From observation this helped the model learn to generate \"__ The answer is _ because _ is _\" answering format faster as compared to omitting this section. Thus we left the formula as it is.\n",
    "\n",
    "__Training Phase__: \n",
    "\n",
    "For training phase, we decided to do optimizer and scheduler at each iteration. Mainly due to observations, having scheduler per epoch does not help the model learn as well as per iteration. We are unable to come to a conclusion however we believe the usage of per-iteration scheduler stepping is favored for lower learning rate schedules and large-scale training, which makes theoretical sense for training GPT. This approach allows the learning rate to gradually and smoothly decay across all training steps. This helps the model converge more steadily and achieve better performance. \n",
    "\n",
    "In contrast, per-epoch scheduler stepping updates the learning rate only once per epoch. While sufficient for simpler schedules or small-scale training with few steps, it is too coarse to fully utilize the benefits of a cosine learning rate schedule in our setup.\n",
    "With per-epoch updates, the learning rate changes only 15 times, making the schedule too coarse to take full advantage of the cosine decay.\n",
    "\n",
    "For safety checks, we printed a progress bar with the loss, steps and learning rate for monitoring. We also decided to, at each epoch test the current model's capabilities from the provided testset + a few additional test qns that align with the math behavior we are trying to achieve. We made it out of 10 to save time as this metric is mostly used for safety testing. So that we can pause training if results are undesirable. We also printed the expected and output for visual confirmation. This is especially useful early on when the catastrophicly forget due to our previous dataset's quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ebeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1/20 step 463/463 loss 0.0571 lr 9.94e-05: : 463it [04:49,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 11 because 11-11 equals 11.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1-10 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 44 because 242-24 equals 442.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 16 because 3*73 equals 66.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 54 because 88+2 equals 5.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 43 because 84-23 equals 30.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 8 because 141/64 equals 99.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 164 because 34*1 equals 188.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 37 because 83*72 equals 7.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 37 because 82-3 equals 3.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 1 accuracy: 0%\n",
      "Saved checkpoint to ../working/dpo_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2/20 step 463/463 loss 0.0324 lr 9.78e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 8 because 1+1 equals 8.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 3 because 1-0 equals 3.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 56 because 42+42 equals 56.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 14 because 3*17 equals 14.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 91 because 72/6 equals 91.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 13 because 72-34 equals 13.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 3 because 44/11 equals 3.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 50 because 72/4 equals 50.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 39 because 72-34 equals 39.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 2 accuracy: 10%\n",
      "Saved checkpoint to ../working/dpo_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3/20 step 463/463 loss 0.0304 lr 9.51e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 7 because 1-1 equals 7.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 2 because 1+0 equals 2.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 85 because 42+42 equals 85.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 223 because 3*17 equals 223.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 4 because 72/4 equals 4.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 41 because 72-34 equals 41.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 1 because 44/11 equals 1.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 497 because 3*17 equals 497.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 23 because 72/44 equals 2.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 5 because 72-34 equals 5.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 3 accuracy: 0%\n",
      "Saved checkpoint to ../working/dpo_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4/20 step 463/463 loss 0.0287 lr 9.14e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=?3,x=? The answer is 11 because 13-1 equals 11.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 0 because 1+0 equals 0.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 89 because 42+42 equals 89.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 13 because 3*17 equals 13.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 27 because 72/4 equals 27.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 4 because 72-34 equals 4.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 6 because 44/11 equals 6.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 23 because 3*17 equals 22.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 42 because 72/4 equals 42.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 37 because 72-34 equals 37.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 4 accuracy: 0%\n",
      "Saved checkpoint to ../working/dpo_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5/20 step 463/463 loss 0.0275 lr 8.68e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1-1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 81 because 42+42 equals 81.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 2 because 72/4 equals 2.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 40 because 72-34 equals 40.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 44 because 44/11 equals 44.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 39 because 3*17 equals 39.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 22 because 72/4 equals 22.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 56 because 72-34 equals 56.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 5 accuracy: 20%\n",
      "Saved checkpoint to ../working/dpo_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6/20 step 463/463 loss 0.0260 lr 8.15e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1-1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1-0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 74 because 42+42 equals 74.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 78 because 3*17 equals 78.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 24 because 72/4 equals 24.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 3 because 44/11 equals 3.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 31 because 3*17 equals 31.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 11 because 72/4 equals 11.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 48 because 72-34 equals 48.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 6 accuracy: 10%\n",
      "Saved checkpoint to ../working/dpo_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7/20 step 463/463 loss 0.0245 lr 7.54e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 10+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 41 because 3*17 equals 41.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 17 because 72/4 equals 17.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 31 because 3*17 equals 31.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 16 because 72/4 equals 16.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 48 because 72-34 equals 48.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 7 accuracy: 30%\n",
      "Saved checkpoint to ../working/dpo_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8/20 step 463/463 loss 0.0236 lr 6.89e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 41 because 3*17 equals 41.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 28 because 72-34 equals 28.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 54 because 3*17 equals 54.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 13 because 72/4 equals 13.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 8 accuracy: 50%\n",
      "Saved checkpoint to ../working/dpo_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9/20 step 463/463 loss 0.0230 lr 6.20e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1+1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 10 because 1+0 equals 10.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 61 because 3*17 equals 61.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 44 because 44/11 equals 44.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 31 because 3*17 equals 31.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 48 because 72-34 equals 48.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 9 accuracy: 30%\n",
      "Saved checkpoint to ../working/dpo_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10/20 step 463/463 loss 0.0228 lr 5.50e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1+1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 0 because 1+0 equals 0.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 27 because 72/4 equals 27.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 43 because 44/11 equals 43.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 28 because 72/4 equals 28.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 10 accuracy: 40%\n",
      "Saved checkpoint to ../working/dpo_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11/20 step 463/463 loss 0.0227 lr 4.80e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? Thenswer is 9 because 1+0 equals 99.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 41 because 3*17 equals 41.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 13 because 72/4 equals 13.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 34 because 44/11 equals 34.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 13 because 72/4 equals 13.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 11 accuracy: 40%\n",
      "Saved checkpoint to ../working/dpo_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12/20 step 463/463 loss 0.0220 lr 4.11e-05: : 463it [04:48,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 10 because 1+0 equals 10.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 23 because 72/4 equals 23.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 12 accuracy: 70%\n",
      "Saved checkpoint to ../working/dpo_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13/20 step 463/463 loss 0.0222 lr 3.46e-05: : 463it [04:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1+1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 10 because 1+0 equals 10.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 61 because 3*17 equals 61.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 17 because 72/4 equals 17.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 23 because 72/4 equals 23.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 13 accuracy: 40%\n",
      "Saved checkpoint to ../working/dpo_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14/20 step 463/463 loss 0.0217 lr 2.85e-05: : 463it [04:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1+1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 41 because 3*17 equals 41.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 41 because 3*17 equals 41.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 14 accuracy: 60%\n",
      "Saved checkpoint to ../working/dpo_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15/20 step 463/463 loss 0.0217 lr 2.32e-05: : 463it [04:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1+1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 47 because 3*17 equals 47.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 31 because 3*17 equals 31.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 15 accuracy: 60%\n",
      "Saved checkpoint to ../working/dpo_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16/20 step 463/463 loss 0.0219 lr 1.86e-05: : 463it [04:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1+1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 94 because 42+42 equals 94.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 28 because 72/4 equals 28.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 41 because 3*17 equals 41.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 16 accuracy: 60%\n",
      "Saved checkpoint to ../working/dpo_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17/20 step 463/463 loss 0.0220 lr 1.49e-05: : 463it [04:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 17 accuracy: 90%\n",
      "Saved checkpoint to ../working/dpo_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18/20 step 463/463 loss 0.0215 lr 1.22e-05: : 463it [04:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 1 because 1+1 equals 1.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 48 because 72-34 equals 48.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 18 accuracy: 70%\n",
      "Saved checkpoint to ../working/dpo_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19/20 step 463/463 loss 0.0217 lr 1.06e-05: : 463it [04:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 13 because 72/4 equals 13.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 19 accuracy: 80%\n",
      "Saved checkpoint to ../working/dpo_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 20/20 step 463/463 loss 0.0216 lr 1.00e-05: : 463it [04:48,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Expected: 1+1=? The answer is 2 because 1+1 equals 2.\n",
      "Output: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Expected: 1+0=? The answer is 1 because 1+0 equals 1.\n",
      "Output: 42+42=? The answer is 84 because 42+42 equals 84.\n",
      "Expected: 17+19=? The answer is 84 because 42+42 equals 84.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 13 because 72/4 equals 13.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Expected: 3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 17 because 72/4 equals 17.\n",
      "Expected: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Epoch 20 accuracy: 70%\n",
      "Saved checkpoint to ../working/dpo.pt\n"
     ]
    }
   ],
   "source": [
    "# Used to calculate accuracy, taken from given test set + some behavior test qns we made\n",
    "test_set = [\"1+1=?\",\"1+0=?\",\"42+42=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "correct_solutions = [\n",
    "    \"1+1=? The answer is 2 because 1+1 equals 2.\",\n",
    "    \"1+0=? The answer is 1 because 1+0 equals 1.\",\n",
    "    \"17+19=? The answer is 84 because 42+42 equals 84.\",\n",
    "    \"3*17=? The answer is 51 because 3*17 equals 51.\",\n",
    "    \"72/4=? The answer is 18 because 72/4 equals 18.\",\n",
    "    \"72-x=34,x=? The answer is 38 because 72-34 equals 38.\",\n",
    "    \"x*11=44,x=? The answer is 4 because 44/11 equals 4.\",\n",
    "    \"3*17=? The answer is 51 because 3*17 equals 51.\",\n",
    "    \"72/4=? The answer is 18 because 72/4 equals 18.\",\n",
    "    \"72-x=34,x=? The answer is 38 because 72-34 equals 38.\"\n",
    "]\n",
    "#plotting variables\n",
    "loss_list=[]\n",
    "iter_list=[]\n",
    "iter_num=0\n",
    "model_accuracy=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(get_batches(lines, batch_size))\n",
    "    for step, (neg_tensor,pos_tensor) in enumerate(pbar):\n",
    "        ###########################################################\n",
    "        # Please complete the training code here!\n",
    "        # Examples: \n",
    "        # ...\n",
    "        # neg_logprob\n",
    "        # pos_logprob \n",
    "        # loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1 \n",
    "        # ...\n",
    "        ###########################################################\n",
    "        neg_logprob = compute_logprob(neg_tensor)\n",
    "        pos_logprob = compute_logprob(pos_tensor)\n",
    "        loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1 \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gpt.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        pbar.set_description(f\"epoch {epoch+1}/{epochs} step {step+1}/{total_steps//epochs} loss {loss.item():.4f} lr {scheduler.get_last_lr()[0]:.2e}\")\n",
    "        # recording loss for plotting\n",
    "        loss_list.append(loss.item())\n",
    "        iter_list.append(iter_num)\n",
    "        iter_num+=1\n",
    "        \n",
    "    # Testing output per epoch + storing results for plotting\n",
    "    correct_ans_count=0\n",
    "    for g in range(len(test_set)):\n",
    "        prompt=encode(test_set[g])\n",
    "        x = torch.tensor([prompt], dtype=torch.long, device=device)\n",
    "        out_ids, _ = gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        output = decode(out_ids[0].tolist())\n",
    "        print(\"Output: \"+output)\n",
    "        print(\"Expected: \"+correct_solutions[g])\n",
    "        if output==correct_solutions[g]:\n",
    "            correct_ans_count=correct_ans_count+1\n",
    "    # Only considering 10 test cases, (mostly taken from initial template's testcase)\n",
    "    model_accuracy.append(correct_ans_count)\n",
    "    print(f\"Epoch {epoch+1} accuracy: {correct_ans_count*10}%\")\n",
    "    \n",
    "    # Saving DPO Checkpoints\n",
    "    if epoch+1<epochs:\n",
    "        ckpt_path=f\"./dpo_{epoch+1}.pt\"\n",
    "    else:\n",
    "        ckpt_path = f\"./dpo.pt\"\n",
    "    torch.save({\n",
    "    \"model_state_dict\": gpt.state_dict(),\n",
    "    \"model_args\": ckpt['model_args'],\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb037812",
   "metadata": {},
   "source": [
    "### Graph Plots (additional) ###\n",
    "\n",
    "To help understand the training, we decided to plot the loss curve graph similar to the additional resources provided (NanoGPT shakespeare). We also plotted an accuracy graph just to visualize its learning clearer. Doing so helps us verify whether there is overfitting, at which epoch does it reach its peak accuracy as well as the general curve. These information helped us further fine-tune variables affecting learning rates, how many epochs we should run as well as determine dataset quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d157f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ensure we plot the actual recorded lists\n",
    "fig, (loss_graph, accuracy_graph) = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "# loss curve (per training step) [copied from nanogpt's extra resources provided]\n",
    "loss_graph.plot(iter_list, loss_list,c=\"blue\",linewidth=0.8)\n",
    "loss_graph.set_xlabel(\"iteration\")\n",
    "loss_graph.set_ylabel(\"loss\")\n",
    "loss_graph.grid(axis='x', color='grey', linestyle='--', linewidth=0.5)\n",
    "loss_graph.grid(axis='y', color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# accuracy curve (per epoch)\n",
    "accuracy_graph.plot(range(1, len(model_accuracy) + 1), model_accuracy, '-o')\n",
    "accuracy_graph.set_xlabel('Epoch No.')\n",
    "accuracy_graph.set_ylabel('correct')\n",
    "accuracy_graph.set_title('Correct answers per epoch (out of 10)')\n",
    "accuracy_graph.set_ylim(0, 10)\n",
    "accuracy_graph.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ac6c9",
   "metadata": {},
   "source": [
    "Based on observations, the loss curve rapidly drops and slowly stabilitizes at 4000 iterations. Knowing that each epoch has 463 iterations. This means the curve stabilitized at 8.639 epoch, which rounds up to 9 epoch. However, we can see from the accuracy chart that the model continues to move in a somewhat positive gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f2ab",
   "metadata": {},
   "source": [
    "### Step 8: Begin testing (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided test cases:\n",
      "Output: 17+19=? The answer is 36 because 17+19 equals 36.\n",
      "Expected:17+19=? The answer is 36 because 17+19 equals 36.\n",
      "Output: 3*17=? The answer is 41 because 3*17 equals 41.\n",
      "Expected:3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected:72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected:72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Output: x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Expected:x*11=44,x=? The answer is 4 because 44/11 equals 4.\n",
      "Output: 3*17=? The answer is 41 because 3*17 equals 41.\n",
      "Expected:3*17=? The answer is 51 because 3*17 equals 51.\n",
      "Output: 72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Expected:72/4=? The answer is 18 because 72/4 equals 18.\n",
      "Output: 72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Expected:72-x=34,x=? The answer is 38 because 72-34 equals 38.\n",
      "Testing from test dataset:\n",
      "Results: 87% correct\n",
      "Output that were wrong.\n",
      "Expected: x/75=77,x=? The answer is 5775 because 77*75 equals 5775.\n",
      "Output: x/75=77,x=? The answer is 5825 because 77*75 equals 5825.\n",
      "Expected: x/21=41,x=? The answer is 861 because 41*21 equals 861.\n",
      "Output: x/21=41,x=? The answer is 801 because 41*21 equals 801.\n",
      "Expected: 67*94=? The answer is 6298 because 67*94 equals 6298.\n",
      "Output: 67*94=? The answer is 6248 because 67*94 equals 6248.\n",
      "Expected: 25*x=2300,x=? The answer is 92 because 2300/25 equals 92.\n",
      "Output: 25*x=2300,x=? The answer is 96 because 2300/25 equals 96.\n",
      "Expected: 4260/x=60,x=? The answer is 71 because 4260/60 equals 71.\n",
      "Output: 4260/x=60,x=? The answer is 61 because 4260/60 equals 61.\n",
      "Expected: 66*x=4026,x=? The answer is 61 because 4026/66 equals 61.\n",
      "Output: 66*x=4026,x=? The answer is 51 because 4026/66 equals 51.\n",
      "Expected: 16*62=? The answer is 992 because 16*62 equals 992.\n",
      "Output: 16*62=? The answer is 912 because 16*62 equals 912.\n",
      "Expected: 51*97=? The answer is 4947 because 51*97 equals 4947.\n",
      "Output: 51*97=? The answer is 5947 because 51*97 equals 5947.\n",
      "Expected: 74*52=? The answer is 3848 because 74*52 equals 3848.\n",
      "Output: 74*52=? The answer is 3828 because 74*52 equals 3828.\n",
      "Expected: 81*13=? The answer is 1053 because 81*13 equals 1053.\n",
      "Output: 81*13=? The answer is 1103 because 81*13 equals 1103.\n",
      "Expected: 83*92=? The answer is 7636 because 83*92 equals 7636.\n",
      "Output: 83*92=? The answer is 7746 because 83*92 equals 7746.\n",
      "Expected: 1650/75=? The answer is 22 because 1650/75 equals 22.\n",
      "Output: 1650/75=? The answer is 26 because 1650/75 equals 26.\n",
      "Expected: x/73=12,x=? The answer is 876 because 12*73 equals 876.\n",
      "Output: x/73=12,x=? The answer is 816 because 12*73 equals 816.\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "ckpt_path = f\"./dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).cuda()\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "# Test\n",
    "gpt.eval()\n",
    "\n",
    "test_set = [\"17+19=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "correct_solutions = [\n",
    "    \"17+19=? The answer is 36 because 17+19 equals 36.\",\n",
    "    \"3*17=? The answer is 51 because 3*17 equals 51.\",\n",
    "    \"72/4=? The answer is 18 because 72/4 equals 18.\",\n",
    "    \"72-x=34,x=? The answer is 38 because 72-34 equals 38.\",\n",
    "    \"x*11=44,x=? The answer is 4 because 44/11 equals 4.\",\n",
    "    \"3*17=? The answer is 51 because 3*17 equals 51.\",\n",
    "    \"72/4=? The answer is 18 because 72/4 equals 18.\",\n",
    "    \"72-x=34,x=? The answer is 38 because 72-34 equals 38.\"\n",
    "]\n",
    "i=0\n",
    "print(\"Provided test cases:\")\n",
    "with torch.no_grad():\n",
    "    for prompt in test_set: \n",
    "        prompt_ids = encode(prompt)\n",
    "        ###########################################################\n",
    "        # Please complete the test code here!\n",
    "        # ...\n",
    "        # gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        # ...\n",
    "        ###########################################################\n",
    "        x = torch.tensor([prompt_ids], dtype=torch.long, device=device)\n",
    "        out_ids, _ = gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        output = decode(out_ids[0].tolist())\n",
    "        print(\"Output: \"+output)\n",
    "        print(\"Expected:\"+correct_solutions[i])\n",
    "        i+=1\n",
    "\n",
    "# More extensive testing using test_dataset\n",
    "print(\"Testing from test dataset:\")\n",
    "sample_test_lines=test_lines\n",
    "correct_answers_count=0\n",
    "wrong_questions=[]\n",
    "for sample_input in sample_test_lines:\n",
    "    prompt_ids = encode(sample_input['negative'].split(' ')[0])\n",
    "    x = torch.tensor([prompt_ids], dtype=torch.long, device=device)\n",
    "    out_ids, _ = gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "    output = decode(out_ids[0].tolist())\n",
    "    if output==sample_input['positive']:\n",
    "        correct_answers_count+=1\n",
    "    else:\n",
    "        wrong_questions.append({'output':output,'expected':sample_input['positive']})\n",
    "print(\"Results: \"+str(correct_answers_count)+\"% correct\")\n",
    "print(\"Output that were wrong.\")\n",
    "for i in wrong_questions:\n",
    "    print(f\"Expected: {i['expected']}\")\n",
    "    print(f\"Output: {i['output']}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef80f74",
   "metadata": {},
   "source": [
    "### Testing and Evaluation\n",
    "\n",
    "For testing, we used the provided testset as well as the 100 test set that was extracted from our generated dataset. We calculated accuracy by checking if the model's output contains the correct answer in the expected format.\n",
    "\n",
    "\n",
    "|  Question  |  Expected Answer  |  Model Output  |  Correct?  |\n",
    "|------------|-------------------|----------------|------------|\n",
    "| 17+19=?   |  The answer is 36 because 17+19 equals 36.  |  The answer is 36 because 17+19 equals 36.  |   ✅    |\n",
    "| 3*17=?    |  The answer is 51 because 3*17 equals 51.   |  The answer is 41 because 3*17 equals 41.   |   ❌    |\n",
    "| 72/4=?    |  The answer is 18 because 72/4 equals 18.   |  The answer is 18 because 72/4 equals 18.   |   ✅    |\n",
    "| 72-x=34,x=? |  The answer is 38 because 72-34 equals 38. |  The answer is 38 because 72-34 equals 38. |   ✅    |\n",
    "| x*11=44,x=? |  The answer is 4 because 44/11 equals 4.   |   The answer is 4 because 44/11 equals 4.   |   ✅    |\n",
    "| 3*17=?    |  The answer is 51 because 3*17 equals 51.   |  The answer is 41 because 3*17 equals 41.   |   ❌    |\n",
    "| 72/4=?    |  The answer is 18 because 72/4 equals 18.   |  The answer is 18 because 72/4 equals 18.   |   ✅    |\n",
    "| 72-x=34,x=? |  The answer is 38 because 72-34 equals 38. |   The answer is 38 because 72-34 equals 38. |   ✅    |\n",
    "\n",
    "\n",
    "We achieved an accuracy of **75%** on the given test set, indicating that the model has learned to solve basic arithmetic problems and provide reasoning in the desired format.\n",
    "\n",
    "We could have made it the accuracy higher if we change the tempeature=`0.5` and top_k=`100`.\n",
    "\n",
    "However, because we wanted to keep a balance between accuracy and diversity of answers where the model is able answer questions not in the training set. We choose to keep the current settings. temperature=`0.8` and top_k=`200`.\n",
    "\n",
    "---\n",
    "\n",
    "### Custom Test Set Evaluation\n",
    "\n",
    "Our custom test set are the 100 math questions that were extracted from our generated dataset but not used during training. This allows us to evaluate the model's ability to generalize to unseen problems while adhering to the desired output format.\n",
    "\n",
    "\n",
    "| Question      | Expected Answer                                        | Model Output                                           | Correct? |\n",
    "| ------------- | ------------------------------------------------------ | ------------------------------------------------------ | -------- |\n",
    "| x/75=77,x=?   | The answer is **5775** because 77*75=5775. | The answer is **5825** because 77*75=5825. | ❌        |\n",
    "| x/21=41,x=?   | The answer is **861** because 41*21=861.               | The answer is **801** because 41*21=801.               | ❌        |\n",
    "| 67*94=?       | The answer is **6298** because 67*94=6298.             | The answer is **6248** because 67*94=6248.             | ❌        |\n",
    "| 25*x=2300,x=? | The answer is **92** because 2300/25=92.               | The answer is **96** because 2300/25=96.               | ❌        |\n",
    "| 4260/x=60,x=? | The answer is **71** because 4260/60=71.               | The answer is **61** because 4260/60=61.               | ❌        |\n",
    "| 66*x=4026,x=? | The answer is **61** because 4026/66=61.               | The answer is **51** because 4026/66=51.               | ❌        |\n",
    "| 16*62=?       | The answer is **992** because 16*62=992.               | The answer is **912** because 16*62=912.               | ❌        |\n",
    "| 51*97=?       | The answer is **4947** because 51*97=4947.             | The answer is **5947** because 51*97=5947.             | ❌        |\n",
    "| 74*52=?       | The answer is **3848** because 74*52=3848.             | The answer is **3828** because 74*52=3828.             | ❌        |\n",
    "| 81*13=?       | The answer is **1053** because 81*13=1053.             | The answer is **1103** because 81*13=1103.             | ❌        |\n",
    "| 83*92=?       | The answer is **7636** because 83*92=7636.             | The answer is **7746** because 83*92=7746.             | ❌        |\n",
    "| 1650/75=?     | The answer is **22** because 1650/75=22.               | The answer is **26** because 1650/75=26.               | ❌        |\n",
    "| x/73=12,x=?   | The answer is **876** because 12*73=876.               | The answer is **816** because 12*73=816.               | ❌        |\n",
    "\n",
    "\n",
    "This table is shows the wrong answers the model produced on our custom test set.\n",
    "\n",
    "Overall, we have achieved an accuracy of **87%** on this custom test set, indicating that while the model has learned some arithmetic operations, it struggles with more complex calculations and generalization to unseen problems.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Analysis of Model Errors\n",
    "\n",
    "Based on observations from the test results, the model demonstrates systematic weaknesses in certain arithmetic operations:\n",
    "\n",
    "**Pattern of Errors:**\n",
    "\n",
    "1. **Multi-digit Multiplication Errors**: \n",
    "   - `67*94=?` → Getting 6248 instead of 6298 (off by 50)\n",
    "   - `51*97=?` → Getting 5947 instead of 4947 (digit reversal)\n",
    "   - `16*62=?` → Getting 912 instead of 992 (off by 80)\n",
    "   \n",
    "2. **Division Errors**:\n",
    "   - `2300/25=?` → Getting 96 instead of 92 (off by 4)\n",
    "   - `1650/75=?` → Getting 26 instead of 22 (off by 4)\n",
    "   - `4260/60=?` → Getting 61 instead of 71 (off by 10)\n",
    "\n",
    "3. **Noticeable Patterns**:\n",
    "   - Model struggles with 2-digit by 2-digit multiplications\n",
    "   - Division errors often show off-by-several-digits mistakes\n",
    "   - The model gets simpler operations (like `72/4=18`) correct\n",
    "   - Basically, the bigger and more complex the math gets, the more the model struggles. It does fine with simple stuff but starts making \"close but not quite\" errors as things get harder.\n",
    "\n",
    "**Root Causes:**\n",
    "\n",
    "1. **Token-Level Arithmetic Limitation**: The model operates at the token level rather than performing true mathematical computation. For complex multi-step calculations (e.g., `3*17`), it relies on pattern recognition from training data rather than actual mathematical reasoning.\n",
    "\n",
    "2. **Insufficient Dataset Coverage**: The dataset (237K samples) may not sufficiently cover all possible all arithmetic operation combinations. Multiplications involving numbers like `17`, `94`, `97` might have been underrepresented during it's training.\n",
    "\n",
    "3. **Overgeneralization**: The model can produce numbers that sound plausible but are actually incorrect, especially for calculations beyond its scope. It should also be noted that achieving full coverage of all arithmetic operations is simply not feasible given the dataset size. Training on a larger dataset would also require significantly more GPU resources.\n",
    "\n",
    "4. **Dynamics of the DPO Learning**: Despite the preference learning setup, the model struggles with problems that require precise arithmetic rather than format adherence. It can successfully learn the desired output format (\"The answer is X because...\") but struggles with producing numerically correct results\n",
    "\n",
    "**Why Simple Operations Succeed:**\n",
    "- Problems like `72/4=18`, `72-34=38`, `44/11=4` are simpler calculations that likely appear frequently in the training data\n",
    "- The model has likely memorized or can easily pattern-match these common arithmetic facts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b43439",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "**Training Limitations:**\n",
    "\n",
    "In the end, our model achieves 75% on the given test set and 87% accuracy on the custom test set, which is reasonable but not perfect. The errors we noted above suggest that while the model learns the desired response format and general mathematical reasoning, it has fundamental limitations in:\n",
    "1. Performing precise arithmetic with large numbers\n",
    "2. Handling operations underrepresented in the training data\n",
    "3. Maintaining accuracy in multi-step calculations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
