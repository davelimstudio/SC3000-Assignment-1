{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79607147",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction\n",
    "The goal of this dataset is to teach the model to reply in the format\n",
    "\"PROMPT The answer is A because B is C\"\n",
    "PROMPT: Being the prompt either in algebra or arithmetic\n",
    "A: Answer\n",
    "B: Reasoning\n",
    "C: Answer\n",
    "\n",
    "After iterating through different negatives, we settled with\n",
    "\"Sorry, I don't know.\" as negatives.\n",
    "We believe due to having variations, made the model output results undesirable. \n",
    "We believe its due to dataset size and learning rate we have configured.\n",
    "If we decreased learning rate while increasing epoch the model starts to gain the system by outputting small changes in A, B or C. However, if we train at a high learning rate, the model is unable to detect a pattern which causes it to catastrophicly forget not only its english abilities, but output gibberish most of the time.\n",
    "Maybe with a larger coverage of edge cases using a larger dataset, we could avoid this. However, due to lack of GPU time available, we decided to settle for less comprehensive reasoning.\n",
    "\n",
    "We initially started of by generating random integers and forming equations. However, this method did not produce good results.\n",
    "After much iterations, The dataset we had most success in was by focusing on different mathematic behaviors.\n",
    "For each equation, we generate arithmetic and algebra versions for it.\n",
    "For Positive generation we generated.\n",
    "1) behavior of 0 when +-* occurs.\n",
    "2) behavior of 1 when */ occurs.\n",
    "3) behavior of systematicly +=*/ values 1-99.\n",
    "4) behavior of tens additions and subtraction.\n",
    "5) behavior of even odds addition.\n",
    "6) behavior of tens multiplications.\n",
    "7) behavior of squares.\n",
    "\n",
    "An observation we had was the model often picks up bad habbits of commonly occuring word patterns. E.g. we had issue with it generating \"1\" and \"1+1\" often. To reduce this behavoir, we decided to skewed number generation to reduce occurences of \"1\" so that the dataset is more balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f54f7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries Import\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "#Global Variables Used\n",
    "old_data=[]\n",
    "data=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11295e02",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d08bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates the lines for a given positive triple.\n",
    "Returns list of dicts (positive, negative) for generating dataset\n",
    "\"\"\"\n",
    "def generate_lines(prompt: str, reasoning: str, ans: int):\n",
    "    pos = f\"{prompt}The answer is {ans} because {reasoning} equals {ans}.\"\n",
    "    toReturn = []\n",
    "    # Based on untrained model output it returns '.' instead of '!' hence changed to .\n",
    "    toReturn.append({\"positive\": pos, \"negative\": prompt+\"Sorry, I do not know.\"})\n",
    "    return toReturn\n",
    "\"\"\"\n",
    "Generates the lines for a given positive triple.\n",
    "Returns list of dicts (positive, prompt) for testing model Performance\n",
    "NOT IN USE ANYMORE\n",
    "\"\"\"\n",
    "def generate_test_lines(prompt: str, reasoning: str, ans: int):\n",
    "    prompt=prompt.rstrip() # remove spacing behind\n",
    "    pos = f\"{prompt} The answer is {ans} because {reasoning} equals {ans}.\"\n",
    "    toReturn = []\n",
    "    toReturn.append({\"positive\": pos, \"prompt\": prompt})\n",
    "    return toReturn\n",
    "\"\"\"\n",
    "Construct Equations\n",
    "Input: (left, Operator, Right, mode)\n",
    "Does: Derieving Answers & Constructing equations \n",
    "      saving results it global variable (data)\n",
    "Output: Boolean\n",
    "\"\"\"\n",
    "def construct_equation(l: int, op: str, r: int,mode=0):\n",
    "    # Derieving answers\n",
    "    if op == \"+\":\n",
    "        ans = l + r\n",
    "    elif op == \"-\":\n",
    "        ans = l - r\n",
    "    elif op == \"*\":\n",
    "        ans = l * r\n",
    "    elif op == \"/\":\n",
    "        ans = l // r\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Arithmetic questions\n",
    "    prompt = f\"{l}{op}{r}=? \"\n",
    "    reasoning = f\"{l}{op}{r}\"\n",
    "    if mode==0:\n",
    "        line1=generate_lines(prompt,reasoning,ans)\n",
    "    else:\n",
    "        line1=generate_test_lines(prompt,reasoning,ans)\n",
    "    \"\"\"\n",
    "    Algebra questions when x is on the left side, e.g. x*5=25,x=?\n",
    "    To convert the arithmetic to algebra we use x (op) r=ans,x=l\n",
    "    e.g. for a arithmetic qns 1+2=3\n",
    "    If we break it down: using l op r=ans\n",
    "    1=l, 2=r, op=+ ans=3\n",
    "    x+2=3,x=1\n",
    "    HENCE, \n",
    "    x+r=ans,x=l\n",
    "    \"\"\"\n",
    "    prompt = f\"x{op}{r}={ans},x=? \"\n",
    "    # For the reasoning we need to invert operators (B)\n",
    "    if op == \"+\":\n",
    "        reasoning = f\"{ans}-{r}\"\n",
    "    elif op == \"-\":\n",
    "        reasoning = f\"{ans}+{r}\"\n",
    "    elif op == \"*\":\n",
    "        reasoning = f\"{ans}/{r}\"\n",
    "    elif op == \"/\":\n",
    "        reasoning = f\"{ans}*{r}\"\n",
    "    else:\n",
    "        reasoning = f\"{ans}{op}{r}\"\n",
    "    currAns = l # (A&C)\n",
    "    if mode==0:\n",
    "        line2=generate_lines(prompt,reasoning,currAns)\n",
    "    else:\n",
    "        line2=generate_test_lines(prompt,reasoning,currAns)\n",
    "\n",
    "    \"\"\"\n",
    "    Algebra questions when x is on the right side, e.g. 5*x=25,x=?\n",
    "    e.g. for a arithmetic qns 1+2=3\n",
    "    If we break it down: using l op r=ans\n",
    "    1=l, 2=r, op=+ ans=3\n",
    "    2+x=3,x=1\n",
    "    HENCE, \n",
    "    l+x=ans,x=r\n",
    "    \"\"\"\n",
    "    prompt = f\"{l}{op}x={ans},x=? \"\n",
    "    \n",
    "    # handle reasoning statements (B)\n",
    "    if op == \"+\":\n",
    "        reasoning = f\"{ans}-{l}\"\n",
    "    elif op == \"-\":\n",
    "        reasoning = f\"{l}{op}{ans}\"\n",
    "    elif op == \"*\":\n",
    "        reasoning = f\"{ans}/{l}\"\n",
    "    elif op == \"/\":\n",
    "        reasoning = f\"{l}/{ans}\"\n",
    "    else:\n",
    "        reasoning = f\"{l}{op}{ans}\"\n",
    "    currAns = r # (A&C)\n",
    "    if mode==0:\n",
    "        line3=generate_lines(prompt,reasoning,currAns)\n",
    "    else:\n",
    "        line3=generate_test_lines(prompt,reasoning,currAns)\n",
    "\n",
    "    # Temp removed since i believe it causes some issues.\n",
    "    # # if operator is *, we need to handle 1x=5,x=? questions as well.\n",
    "    # # Where * is omited for simplicity\n",
    "    # if op == \"*\":\n",
    "    #     prompt3 = f\"{l}{op}x={ans},x=? \"\n",
    "    #     for v in generate_lines(prompt3, reason3_expr, r, reason3_res):\n",
    "    #         data.append(v)\n",
    "\n",
    "    # Append all 3 \n",
    "    if(mode==1):\n",
    "        old_positives = set(item[0][\"positive\"] for item in old_data)\n",
    "        for line in [line1, line2, line3]:\n",
    "            # Each line is a list with one dict, so extract the dict\n",
    "            for entry in line:\n",
    "                if entry[\"positive\"] not in old_positives:\n",
    "                    data.append(entry)\n",
    "        return True\n",
    "    else:\n",
    "        data.append(line1)\n",
    "        data.append(line2)\n",
    "        data.append(line3)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686fbb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43149033",
   "metadata": {},
   "source": [
    "# Code for positive behavior generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb49fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teaches behavior when 0 (+-*) occurs.\n",
    "for x in range(0, 101):\n",
    "    construct_equation(0, \"+\", x)\n",
    "    construct_equation(x, \"-\", 0)\n",
    "    construct_equation(x, \"*\", 0)\n",
    "    # No need divide cuz divide by zero is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ac87828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teaches behavior when 1 (*/) occurs.\n",
    "for x in range(1, 101):\n",
    "    construct_equation(x, \"*\", 1)\n",
    "    construct_equation(1, \"*\", x)\n",
    "    construct_equation(x, \"/\", 1)\n",
    "    # not training fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c7300b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teaches behavior of systemeticly +-*/ for 1-99 integers again, trying to reduce 1s\n",
    "for l in range(1, 100):\n",
    "    for r in range(2, 100):\n",
    "        construct_equation(l, \"+\", r)\n",
    "        construct_equation(r, \"+\", l)\n",
    "        construct_equation(l + r, \"-\", r)\n",
    "        construct_equation(l + r, \"-\", l)\n",
    "        construct_equation(l, \"*\", r)\n",
    "        construct_equation(r, \"*\", l)\n",
    "        if r != 0:\n",
    "            construct_equation(l * r, \"/\", r)\n",
    "        if l != 0:\n",
    "            construct_equation(l * r, \"/\", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2103b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teaches behavior of tens additions exclude 1 to skew it to print less 1s\n",
    "for l in range(10, 101, 10):\n",
    "    for r in range(2, 10):\n",
    "        construct_equation(l, \"+\", r)\n",
    "        construct_equation(r, \"+\", l)\n",
    "        construct_equation(l + r, \"-\", r)\n",
    "        construct_equation(l + r, \"-\", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0e8d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teaches behavior of Even odd addition trying to reduce 1s again\n",
    "evens = list(range(2, 21, 2))\n",
    "odds = list(range(3, 20, 2))\n",
    "for e1 in evens:\n",
    "    for e2 in evens:\n",
    "        construct_equation(e1, \"+\", e2)\n",
    "    for o in odds:\n",
    "        construct_equation(e1, \"+\", o)\n",
    "for o1 in odds:\n",
    "    for o2 in odds:\n",
    "        construct_equation(o1, \"+\", o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf77bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teaches behavior of tens multiplications since model has some difficulty in multiply and divide\n",
    "for l in range(10, 101, 10):\n",
    "    for r in range(1, 11):\n",
    "        construct_equation(l, \"*\", r)\n",
    "        construct_equation(r, \"*\", l)\n",
    "        ll, rr = l, r\n",
    "        if ll < rr:\n",
    "            ll, rr = rr, ll\n",
    "        if ll % rr != 0:\n",
    "            ll -= ll % rr\n",
    "        construct_equation(ll, \"/\", rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb750f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behaviors for squares just alittle extra\n",
    "for x in range(1, 11):\n",
    "    construct_equation(x, \"*\", x)\n",
    "    construct_equation(x * x, \"/\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "198a0879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 237390 pairs, storing in dataset_final.json\n"
     ]
    }
   ],
   "source": [
    "# Save data in json\n",
    "flat_data = [item for sublist in data for item in sublist]\n",
    "with open(\"dataset_final.json\", \"w\") as f:\n",
    "    json.dump(flat_data, f, indent=2)\n",
    "print(f\"Generated {len(flat_data)} pairs, storing in dataset_final.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
